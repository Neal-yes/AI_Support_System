name: CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      # 使用隔离的 metrics 集合以避免与默认集合冲突
      METRICS_TEST_COLLECTION: metrics_demo_1d
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start API stack (docker-compose) and wait for health
        env:
          API_PORT: "8000"
        run: |
          set -euo pipefail
          echo "[CI] Preparing .env from configs/env.example"
          cp configs/env.example .env
          # Ensure API port is 8000 for local exposure
          sed -i 's/^API_PORT=.*/API_PORT=8000/' .env || true
          # Export OLLAMA_MODEL to job env as MODEL (used by smoke test)
          MODEL_FROM_ENV=$(grep -E '^OLLAMA_MODEL=' .env | head -n1 | cut -d= -f2- || true)
          if [ -n "${MODEL_FROM_ENV:-}" ]; then
            echo "MODEL=${MODEL_FROM_ENV}" >> "$GITHUB_ENV"
            echo "[CI] Using MODEL from .env: ${MODEL_FROM_ENV}"
          else
            echo "[CI] No OLLAMA_MODEL found in .env; defaulting MODEL to qwen2.5:7b"
            echo "MODEL=qwen2.5:7b" >> "$GITHUB_ENV"
          fi

          echo "[CI] Docker/Compose versions"
          docker --version
          docker compose version || true

          echo "[CI] Pull lightweight dependencies in background (best-effort)"
          docker compose pull db redis qdrant ollama || true

          echo "[CI] Build API image"
          docker compose build api

          echo "[CI] Bring up dependencies first"
          docker compose up -d db redis qdrant ollama

          echo "[CI] Bring up API"
          docker compose up -d api

          echo "[CI] Wait for API health on http://localhost:${API_PORT}/metrics"
          ok=0
          for i in $(seq 1 60); do
            if curl -fsS "http://localhost:${API_PORT}/metrics" >/dev/null 2>&1; then
              echo "[CI] API healthy (metrics reachable)"
              ok=1; break
            fi
            sleep 2
          done
          if [ "$ok" != "1" ]; then
            echo "[CI] API did not become healthy in time; showing logs for debugging" >&2
            docker compose ps
            docker compose logs --no-color --timestamps api || true
            exit 1
          fi

          echo "[CI] Wait for Ollama service on http://localhost:11434/api/tags"
          ok=0
          for i in $(seq 1 30); do
            if curl -fsS "http://localhost:11434/api/tags" >/dev/null 2>&1; then
              echo "[CI] Ollama healthy (tags endpoint reachable)"
              ok=1; break
            fi
            sleep 3
          done
          if [ "$ok" != "1" ]; then
            echo "[CI] Ollama did not become healthy in time; showing logs for debugging" >&2
            docker compose ps
            docker compose logs --no-color --timestamps ollama || true
            exit 1
          fi

          echo "[CI] Pre-pull model in Ollama to avoid 404 (model not found)"
          set +e
          PULL_NAME="${MODEL:-${MODEL_FROM_ENV:-qwen2.5:7b}}"
          curl -fsS -X POST http://localhost:11434/api/pull \
            -H 'Content-Type: application/json' \
            -d "{\"name\": \"${PULL_NAME}\"}" || true
          echo "[CI] Waiting for model tag to appear: ${PULL_NAME}"
          ok=0
          for i in $(seq 1 60); do
            if curl -fsS http://localhost:11434/api/tags | jq -e --arg m "${PULL_NAME}" '.models[].model == $m' >/dev/null 2>&1; then
              echo "[CI] Model available: ${PULL_NAME}"
              ok=1; break
            fi
            sleep 5
          done
          set -e
          if [ "$ok" != "1" ]; then
            echo "[CI] Model ${PULL_NAME} not ready in time; proceeding but smoke may fail" >&2
          fi

      - name: Run tests
        env:
          API_BASE_URL: http://localhost:8000
        run: pytest -q -k 'not sse_stream_ci'

      - name: Backup health check (Qdrant collections)
        if: always()
        run: |
          set -euo pipefail
          mkdir -p artifacts/metrics
          URL="http://localhost:6333/collections"
          echo "[CI] Fetching Qdrant collections from ${URL}"
          if curl -fsS "$URL" -o artifacts/metrics/backup_health.json; then
            echo "[CI] Wrote artifacts/metrics/backup_health.json"
          else
            echo "{\"error\":\"qdrant_unreachable\"}" > artifacts/metrics/backup_health.json
            echo "[CI][warn] Qdrant unreachable; wrote fallback backup_health.json"
          fi

      - name: Upload backup health json
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backup-health-json
          path: artifacts/metrics/backup_health.json
          retention-days: 7
          if-no-files-found: warn

      - name: Prepare RAG demo embeddings
        if: false
        env:
          RAG_COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          echo "[CI] Preparing demo embeddings for RAG"
          bash scripts/ci/prepare_demo_embeddings.sh

      - name: Smoke ask (plain + RAG)
        if: false
        env:
          COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          echo "[CI] Smoke will use MODEL=${MODEL:-<unset>} COLLECTION=${COLLECTION:-<unset>}"
          bash scripts/ci/smoke_ask.sh

      - name: Assert Smoke PASS
        if: false
        run: |
          set -euo pipefail
          if [ -f artifacts/metrics/smoke_summary.md ]; then
            if ! grep -qE '^- result: PASS$' artifacts/metrics/smoke_summary.md; then
              echo "Smoke summary indicates failure or missing PASS:" >&2
              sed -n '1,200p' artifacts/metrics/smoke_summary.md >&2 || true
              exit 1
            fi
          else
            echo "smoke_summary.md not found; failing to avoid false positives." >&2
            ls -la artifacts/metrics || true
            exit 1
          fi

      - name: RAG evaluation gate
        if: false
        env:
          # M1 基线阈值（技术计划 2.10，门禁仅包含已实现的指标）
          GATE_HIT_RATIO_MIN: "0.60"
          GATE_AVG_TOP1_MIN: "0.35"
          GATE_STRICT: "both"
          GATE_MIN_TOTAL: "10"
          GATE_REQUIRE_MIN_TOTAL: "0"
          RAG_EVAL_QUERIES: queries/rag_eval_50.jsonl
          RAG_TOP_K: "5"
          # 关键：将隔离集合名传入 RAG gate，避免 fallback 到默认集合
          RAG_COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          bash scripts/ci/rag_eval_gate.sh

      - name: CI Summary (RAG & Smoke)
        if: false
        run: |
          mkdir -p artifacts/metrics
          SUMMARY_FILE="artifacts/metrics/ci_step_summary.md"

          echo "## RAG Gate Summary" >> "$GITHUB_STEP_SUMMARY"
          # Explicitly include isolated collection so later assert checks within the same step summary
          echo "- collection: ${METRICS_TEST_COLLECTION}" >> "$GITHUB_STEP_SUMMARY"
          echo "## RAG Gate Summary" >> "$SUMMARY_FILE"
          echo "- collection: ${METRICS_TEST_COLLECTION}" >> "$SUMMARY_FILE"
          if [ -f artifacts/metrics/rag_eval.json ]; then
            HR=$(jq -r '.summary.hit_ratio // 0' artifacts/metrics/rag_eval.json)
            AT1=$(jq -r '.summary.avg_top1 // 0' artifacts/metrics/rag_eval.json)
            TOT=$(jq -r '.summary.total // 0' artifacts/metrics/rag_eval.json)
            echo "- total: ${TOT}" >> "$GITHUB_STEP_SUMMARY"
            echo "- hit_ratio: ${HR}" >> "$GITHUB_STEP_SUMMARY"
            echo "- avg_top1: ${AT1}" >> "$GITHUB_STEP_SUMMARY"
            echo "- total: ${TOT}" >> "$SUMMARY_FILE"
            echo "- hit_ratio: ${HR}" >> "$SUMMARY_FILE"
            echo "- avg_top1: ${AT1}" >> "$SUMMARY_FILE"
            if [ -f artifacts/metrics/rag_eval.csv ]; then
              echo "- csv: artifacts/metrics/rag_eval.csv (in artifacts)" >> "$GITHUB_STEP_SUMMARY"
              echo "- csv: artifacts/metrics/rag_eval.csv (in artifacts)" >> "$SUMMARY_FILE"
            fi
          else
            echo "- rag_eval.json not found" >> "$GITHUB_STEP_SUMMARY"
            echo "- rag_eval.json not found" >> "$SUMMARY_FILE"
          fi

          # Newline then the Smoke section header; echo -e is shell-dependent, so use printf
          printf "\n## Smoke Ask\n" >> "$GITHUB_STEP_SUMMARY"
          echo "- collection: ${METRICS_TEST_COLLECTION}" >> "$GITHUB_STEP_SUMMARY"
          printf "\n## Smoke Ask\n" >> "$SUMMARY_FILE"
          echo "- collection: ${METRICS_TEST_COLLECTION}" >> "$SUMMARY_FILE"
          P_STATUS=$(cat artifacts/metrics/ask_plain.status 2>/dev/null || echo "missing")
          R_STATUS=$(cat artifacts/metrics/ask_rag.status 2>/dev/null || echo "missing")
          echo "- plain: ${P_STATUS}" >> "$GITHUB_STEP_SUMMARY"
          echo "- rag: ${R_STATUS}" >> "$GITHUB_STEP_SUMMARY"
          echo "- plain: ${P_STATUS}" >> "$SUMMARY_FILE"
          echo "- rag: ${R_STATUS}" >> "$SUMMARY_FILE"

      - name: Assert CI Summary includes isolated collection
        if: false
        run: |
          set -euo pipefail
          SUMMARY_FILE="artifacts/metrics/ci_step_summary.md"
          if [ ! -f "$SUMMARY_FILE" ]; then
            echo "${SUMMARY_FILE} not found; failing." >&2
            exit 1
          fi
          echo "[CI] Verify step summary contains isolated collection and sections"
          if ! grep -q 'metrics_demo_1d' "$SUMMARY_FILE"; then
            echo "Missing metrics_demo_1d in step summary" >&2
            sed -n '1,200p' "$SUMMARY_FILE" >&2 || true
            exit 1
          fi
          if ! grep -qE '^## RAG Gate Summary' "$SUMMARY_FILE"; then
            echo "Missing RAG Gate Summary header in step summary" >&2
            sed -n '1,200p' "$SUMMARY_FILE" >&2 || true
            exit 1
          fi
          if ! grep -qE '^## Smoke Ask' "$SUMMARY_FILE"; then
            echo "Missing Smoke Ask header in step summary" >&2
            sed -n '1,200p' "$SUMMARY_FILE" >&2 || true
            exit 1
          fi

      - name: Assert artifacts present
        if: false
        run: |
          set -euo pipefail
          echo "[CI] Listing artifacts/metrics"
          ls -la artifacts/metrics || true
          for f in ci_step_summary.md rag_eval.csv smoke_summary.md; do
            if [ ! -f "artifacts/metrics/$f" ]; then
              echo "Missing artifacts/metrics/$f" >&2
              exit 1
            fi
          done

      - name: Assert rag_eval.csv summary matches isolated collection & thresholds
        if: false
        env:
          # 与 RAG evaluation gate 使用的阈值对齐
          GATE_HIT_RATIO_MIN: "0.60"
          GATE_AVG_TOP1_MIN: "0.35"
        run: |
          set -euo pipefail
          FILE="artifacts/metrics/rag_eval.csv"
          if [ ! -f "$FILE" ]; then
            echo "$FILE not found" >&2
            exit 1
          fi
          # Find the aggregated summary line for the isolated collection
          LINE=$(awk -F, -v c="${METRICS_TEST_COLLECTION}" '$1==c{print; found=1} END{if(!found) exit 2}' "$FILE") || {
            echo "Summary for ${METRICS_TEST_COLLECTION} not found in rag_eval.csv" >&2
            tail -n 10 "$FILE" >&2 || true
            exit 1
          }
          # Parse fields: collection,total,hit_ratio,avg_top1,avg_mean_score,top_k
          COLL=$(echo "$LINE" | cut -d, -f1)
          TOTAL=$(echo "$LINE" | cut -d, -f2)
          HITR=$(echo "$LINE" | cut -d, -f3)
          AT1=$(echo "$LINE" | cut -d, -f4)
          MEAN=$(echo "$LINE" | cut -d, -f5)
          TOPK=$(echo "$LINE" | cut -d, -f6)
          echo "[CI] rag_eval summary: coll=$COLL total=$TOTAL hit_ratio=$HITR avg_top1=$AT1 avg_mean=$MEAN top_k=$TOPK"
          # Basic sanity checks against expected isolated collection and known config
          if [ "$COLL" != "${METRICS_TEST_COLLECTION}" ]; then
            echo "Unexpected collection in summary: $COLL (want ${METRICS_TEST_COLLECTION})" >&2
            exit 1
          fi
          # Expect at least 10 queries and top_k=5 per workflow config
          if [ "${TOTAL}" -lt 10 ]; then
            echo "Total <$TOTAL> is unexpectedly small (expect >=10)" >&2
            exit 1
          fi
          if [ "${TOPK}" != "5" ]; then
            echo "Unexpected top_k: $TOPK (expect 5)" >&2
            exit 1
          fi
          # Threshold checks (numeric). Use awk for float comparisons.
          awk -v v="$HITR" -v m="$GATE_HIT_RATIO_MIN" 'BEGIN{if (v+0 < m+0) {exit 1}}' || {
            echo "hit_ratio $HITR is below min $GATE_HIT_RATIO_MIN" >&2
            exit 1
          }
          awk -v v="$AT1" -v m="$GATE_AVG_TOP1_MIN" 'BEGIN{if (v+0 < m+0) {exit 1}}' || {
            echo "avg_top1 $AT1 is below min $GATE_AVG_TOP1_MIN" >&2
            exit 1
          }

      - name: Upload metrics artifacts
        if: false
        uses: actions/upload-artifact@v4
        with:
          name: metrics-and-reports
          path: |
            artifacts/metrics/*
          if-no-files-found: ignore

  sse-test:
    runs-on: ubuntu-latest
    needs: [test]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start API stack (docker-compose) and wait for health
        env:
          API_PORT: "8000"
        run: |
          set -euo pipefail
          cp configs/env.example .env
          sed -i 's/^API_PORT=.*/API_PORT=8000/' .env || true
          docker compose build api
          docker compose up -d db redis qdrant ollama
          docker compose up -d api
          ok=0
          for i in $(seq 1 60); do
            if curl -fsS "http://localhost:${API_PORT}/metrics" >/dev/null 2>&1; then ok=1; break; fi
            sleep 2
          done
          if [ "$ok" != "1" ]; then
            docker compose ps
            docker compose logs --no-color --timestamps api || true
            exit 1
          fi
          # Ensure Ollama is up (best-effort)
          for i in $(seq 1 30); do
            if curl -fsS "http://localhost:11434/api/tags" >/dev/null 2>&1; then break; fi
            sleep 3
          done
          echo "[CI][sse-test] Determine model tag from .env (OLLAMA_MODEL) or fallback"
          MODEL_FROM_ENV=$(grep -E '^OLLAMA_MODEL=' .env | head -n1 | cut -d= -f2- || true)
          PULL_NAME="${MODEL_FROM_ENV:-qwen2.5:7b}"
          echo "[CI][sse-test] Pre-pull model in Ollama: ${PULL_NAME}"
          set +e
          curl -fsS -X POST http://localhost:11434/api/pull \
            -H 'Content-Type: application/json' \
            -d "{\"name\": \"${PULL_NAME}\"}" || true
          echo "[CI][sse-test] Waiting for model tag to appear: ${PULL_NAME}"
          ok=0
          for i in $(seq 1 60); do
            if curl -fsS http://localhost:11434/api/tags | jq -e --arg m "${PULL_NAME}" '.models[].model == $m' >/dev/null 2>&1; then
              echo "[CI][sse-test] Model available: ${PULL_NAME}"
              ok=1; break
            fi
            sleep 5
          done
          set -e
          if [ "$ok" != "1" ]; then
            echo "[CI][sse-test] Model ${PULL_NAME} not ready in time; continuing, SSE may be slower to first token" >&2
          fi

          echo "[CI][sse-test] API warmup via /api/v1/debug/warmup"
          curl -fsS "http://localhost:${API_PORT}/api/v1/debug/warmup" || true

      - name: Run SSE test only
        env:
          API_BASE_URL: http://localhost:8000
        run: pytest -q tests/test_sse_stream_ci.py

  smoke:
    runs-on: ubuntu-latest
    needs: [test]
    env:
      METRICS_TEST_COLLECTION: metrics_demo_1d
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start API stack (docker-compose)
        env:
          API_PORT: "8000"
        run: |
          set -euo pipefail
          cp configs/env.example .env
          sed -i 's/^API_PORT=.*/API_PORT=8000/' .env || true
          docker compose build api
          docker compose up -d db redis qdrant ollama
          docker compose up -d api
          # Wait API
          for i in $(seq 1 60); do
            if curl -fsS "http://localhost:${API_PORT}/metrics" >/dev/null 2>&1; then break; fi
            sleep 2
          done
          # Best-effort ensure Ollama
          for i in $(seq 1 30); do
            if curl -fsS "http://localhost:11434/api/tags" >/dev/null 2>&1; then break; fi
            sleep 3
          done

      - name: Prepare RAG demo embeddings
        env:
          RAG_COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          echo "[CI] Preparing demo embeddings for RAG"
          bash scripts/ci/prepare_demo_embeddings.sh

      - name: Smoke ask (plain + RAG)
        env:
          COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          echo "[CI] Smoke will use MODEL=${MODEL:-<unset>} COLLECTION=${COLLECTION:-<unset>}"
          bash scripts/ci/smoke_ask.sh

      - name: Assert Smoke PASS
        run: |
          set -euo pipefail
          if [ -f artifacts/metrics/smoke_summary.md ]; then
            if ! grep -qE '^- result: PASS$' artifacts/metrics/smoke_summary.md; then
              echo "Smoke summary indicates failure or missing PASS:" >&2
              sed -n '1,200p' artifacts/metrics/smoke_summary.md >&2 || true
              exit 1
            fi
          else
            echo "smoke_summary.md not found; failing to avoid false positives." >&2
            ls -la artifacts/metrics || true
            exit 1
          fi

      - name: Ensure smoke summary exists (on failure)
        if: always()
        run: |
          mkdir -p artifacts/metrics
          if [ ! -f artifacts/metrics/smoke_summary.md ]; then
            {
              echo "## Smoke Summary"
              echo "- result: FAIL"
              echo "- note: generated by CI because smoke steps failed or no summary was produced"
              echo "- job: ${GITHUB_JOB}"
              echo "- run_id: ${GITHUB_RUN_ID}"
            } > artifacts/metrics/smoke_summary.md
          fi
 
      - name: Upload smoke summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-summary-md
          path: artifacts/metrics/smoke_summary.md
          retention-days: 7
          if-no-files-found: warn

      - name: Upload smoke raw outputs (ask plain/rag)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-raw
          path: |
            artifacts/metrics/ask_plain.*
            artifacts/metrics/ask_rag.*
          retention-days: 7
          if-no-files-found: warn

  rag-gate:
    runs-on: ubuntu-latest
    needs: [test]
    env:
      METRICS_TEST_COLLECTION: metrics_demo_1d
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start API stack (docker-compose)
        env:
          API_PORT: "8000"
        run: |
          set -euo pipefail
          cp configs/env.example .env
          sed -i 's/^API_PORT=.*/API_PORT=8000/' .env || true
          docker compose build api
          docker compose up -d db redis qdrant ollama
          docker compose up -d api
          # Wait API
          for i in $(seq 1 60); do
            if curl -fsS "http://localhost:${API_PORT}/metrics" >/dev/null 2>&1; then break; fi
            sleep 2
          done
          # Best-effort ensure Ollama
          for i in $(seq 1 30); do
            if curl -fsS "http://localhost:11434/api/tags" >/dev/null 2>&1; then break; fi
            sleep 3
          done

      - name: Prepare RAG demo embeddings
        env:
          RAG_COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          echo "[CI] Preparing demo embeddings for RAG (rag-gate)"
          bash scripts/ci/prepare_demo_embeddings.sh

      - name: RAG evaluation gate
        env:
          GATE_HIT_RATIO_MIN: "0.60"
          GATE_AVG_TOP1_MIN: "0.35"
          GATE_STRICT: "both"
          GATE_MIN_TOTAL: "10"
          GATE_REQUIRE_MIN_TOTAL: "0"
          RAG_TOP_K: "5"
          RAG_COLLECTION: ${{ env.METRICS_TEST_COLLECTION }}
        run: |
          bash scripts/ci/rag_eval_gate.sh

      - name: Upload rag gate artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rag-eval-csv
          path: artifacts/metrics/rag_eval.csv
          retention-days: 7
          if-no-files-found: warn

      - name: Upload rag gate JSON
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rag-eval-json
          path: artifacts/metrics/rag_eval.json
          retention-days: 7
          if-no-files-found: warn

  frontend-e2e:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend deps
        working-directory: frontend
        run: |
          npm install --no-fund --no-audit

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install Playwright browsers (with dependencies)
        working-directory: frontend
        run: npx playwright install --with-deps

      - name: Run Playwright E2E
        working-directory: frontend
        env:
          # Ensure non-interactive CI run
          CI: 'true'
        run: npm run test:e2e

      - name: Summarize Playwright JUnit results
        if: always()
        run: |
          FILE="frontend/playwright-results.xml"
          if [ -f "$FILE" ]; then
            TS=$(grep -o 'tests="[0-9]*"' "$FILE" | head -1 | sed 's/[^0-9]//g' || echo 0)
            FS=$(grep -o 'failures="[0-9]*"' "$FILE" | head -1 | sed 's/[^0-9]//g' || echo 0)
            SK=$(grep -o 'skipped="[0-9]*"' "$FILE" | head -1 | sed 's/[^0-9]//g' || echo 0)
            echo "## Playwright Summary" >> "$GITHUB_STEP_SUMMARY"
            echo "- tests: $TS" >> "$GITHUB_STEP_SUMMARY"
            echo "- failures: $FS" >> "$GITHUB_STEP_SUMMARY"
            echo "- skipped: $SK" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "## Playwright Summary" >> "$GITHUB_STEP_SUMMARY"
            echo "- junit file not found (frontend/playwright-results.xml)" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Collect failed snapshots (screenshots/videos)
        if: always()
        run: |
          mkdir -p frontend/failed-snapshots || true
          # Collect images and videos for quick inspection
          find frontend/test-results -type f \( -name '*.png' -o -name '*.webm' \) -print -exec cp {} frontend/failed-snapshots/ \; || true

      - name: Upload Playwright HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: frontend/playwright-report
          retention-days: 7
          if-no-files-found: warn

      - name: Upload Playwright raw test-results (traces/screenshots/videos)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-test-results
          path: frontend/test-results
          retention-days: 7
          if-no-files-found: warn

      - name: Upload Playwright failed snapshots (quick view)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-failed-snapshots
          path: frontend/failed-snapshots
          retention-days: 7
          if-no-files-found: warn

      - name: Upload Playwright JUnit XML
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-junit-xml
          path: frontend/playwright-results.xml
          retention-days: 7
          if-no-files-found: warn
