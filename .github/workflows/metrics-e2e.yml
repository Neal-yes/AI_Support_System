name: Metrics E2E

on:
  workflow_dispatch:
    inputs:
      gate_hit_ratio_min:
        description: "Override GATE_HIT_RATIO_MIN (e.g., 0.65)"
        required: false
        type: string
      gate_avg_top1_min:
        description: "Override GATE_AVG_TOP1_MIN (e.g., 0.35)"
        required: false
        type: string
      gate_strict:
        description: "Gate mode: both|either"
        required: false
        type: string
      gate_min_total:
        description: "Minimum eval samples required (e.g., 10)"
        required: false
        type: string
      gate_require_min_total:
        description: "Require min total strictly: 0|1"
        required: false
        type: string
  push:
    branches: [ main, master ]

jobs:
  e2e-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: Debug working directory
        run: |
          echo "PWD:" && pwd
          echo "Root listing:" && ls -la
          echo "configs listing:" && ls -la configs || true
          echo "docker-compose.yml exists?" && [ -f docker-compose.yml ] && echo yes || echo no

      - name: Set up Docker Compose
        run: docker compose version

      - name: Prepare .env for Compose
        run: |
          if [ -f configs/env.example ]; then
            cp -f configs/env.example .env
            echo "Prepared .env from configs/env.example"
          elif [ -f .env ]; then
            echo ".env already exists in repo root, using it"
          else
            echo "configs/env.example and .env not found, generating minimal .env"
            {
              echo "COMPOSE_PROJECT_NAME=ai_support";
              echo "GRAFANA_ADMIN_USER=admin";
              echo "GRAFANA_ADMIN_PASSWORD=admin";
            } > .env
          fi

      - name: Tighten ai_support_rag_ask p95 thresholds by branch
        run: |
          set -euo pipefail
          BRANCH="${GITHUB_REF_NAME}"
          echo "Branch: $BRANCH"

          LLM_P95="2.0"
          RAG_P95="1.0"
          case "$BRANCH" in
            release/*)
              # Release: more strict p95 thresholds
              LLM_P95="1.5"
              RAG_P95="0.8"
              ;;
            *) ;;
          esac

          file="configs/rules/ai_support_rules.yml"
          echo "Setting LLM p95 to ${LLM_P95}, RAG p95 to ${RAG_P95} in ${file}"
          # Only modify the two RAG/ASK related rules by matching metric names
          if [ -f "$file" ]; then
            sed -i -E "s/(llm_generate_duration_seconds_bucket.*> )[0-9.]+/\1${LLM_P95}/" "$file"
            sed -i -E "s/(rag_retrieval_duration_seconds_bucket.*> )[0-9.]+/\1${RAG_P95}/" "$file"
          else
            echo "Rules file not found at $file, skipping threshold tightening."
          fi

      - name: Set model name
        run: |
          # Allow override via workflow env or inputs; default to a tiny model for CI reliability
          echo "MODEL_SMALL=${MODEL_SMALL:-qwen2:0.5b}" >> "$GITHUB_ENV"

      - name: Start stack (api, prometheus, grafana, redis, qdrant, alertmanager, ollama)
        run: |
          docker compose -f docker-compose.yml pull || true
          docker compose -f docker-compose.yml up -d api prometheus grafana redis qdrant alertmanager ollama

      - name: Wait for services
        run: |
          echo "Waiting for API (http://localhost:8000/metrics)"
          for i in {1..40}; do curl -fsS http://localhost:8000/metrics && break || sleep 5; done
          echo "Waiting for Prometheus (http://localhost:9090/-/ready)"
          for i in {1..40}; do curl -fsS http://localhost:9090/-/ready && break || sleep 5; done
          echo "Waiting for Grafana (http://localhost:3000/login)"
          for i in {1..40}; do curl -fsS -o /dev/null -w "%{http_code}\n" http://localhost:3000/login | grep -E "^(200|302)$" && break || sleep 5; done
          echo "Waiting for Ollama (http://localhost:11434)"
          for i in {1..40}; do curl -fsS http://localhost:11434/api/tags && break || sleep 5; done

      - name: Pull small Ollama model
        run: |
          set -e
          echo "Pulling model: ${MODEL_SMALL}"
          for i in {1..3}; do
            if docker exec ai_support_ollama ollama pull "${MODEL_SMALL}"; then
              break
            fi
            echo "Model pull failed (attempt $i), retrying in 10s..."
            sleep 10
          done

      - name: Install script deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl

      - name: Login Grafana and fetch alert JSON
        env:
          GRAFANA_USER: ${{ secrets.GRAFANA_USER }}
          GRAFANA_PASS: ${{ secrets.GRAFANA_PASS }}
        run: |
          set -e
          mkdir -p artifacts/metrics
          if [ -n "${GRAFANA_USER}" ] && [ -n "${GRAFANA_PASS}" ]; then
            echo "Logging into Grafana..."
            curl -fsS -c artifacts/metrics/grafana_cookies.txt \
              -H 'Content-Type: application/json' \
              -d "{\"user\":\"${GRAFANA_USER}\",\"password\":\"${GRAFANA_PASS}\"}" \
              http://localhost:3000/login > /dev/null
            echo "Fetching Grafana alert rules and active alerts..."
            curl -fsS -b artifacts/metrics/grafana_cookies.txt \
              http://localhost:3000/api/alert-rules \
              -o artifacts/metrics/grafana_alert_rules.json || true
            curl -fsS -b artifacts/metrics/grafana_cookies.txt \
              http://localhost:3000/api/alertmanager/grafana/api/v2/alerts \
              -o artifacts/metrics/grafana_active_alerts.json || true
          else
            echo "GRAFANA_USER/GRAFANA_PASS not set in Secrets, skip Grafana fetch."
          fi

      - name: Export Grafana dashboard JSON
        run: |
          set +e
          mkdir -p artifacts/metrics
          DASH_UID=ai-support-export-download
          if [ -f artifacts/metrics/grafana_cookies.txt ]; then
            echo "Export with cookie for dashboard UID=${DASH_UID}"
            curl -fsS -b artifacts/metrics/grafana_cookies.txt \
              "http://localhost:3000/api/dashboards/uid/${DASH_UID}" \
              -o artifacts/metrics/grafana_dashboard_${DASH_UID}.json || true
          else
            echo "No Grafana login cookie found; skip dashboard export (auth likely required)."
          fi

      - name: Run metrics verification script
        run: |
          set -euo pipefail
          echo "Bash: $(bash --version | head -n1)"
          echo "PWD=$(pwd)"
          echo "Repo root listing:" && ls -la
          echo "Scripts listing (relative):" && ls -la scripts || true
          echo "Scripts listing (abs):" && ls -la "$GITHUB_WORKSPACE/scripts" || true
          echo "Checking required CLI tools..."
          if ! command -v jq >/dev/null 2>&1 || ! command -v curl >/dev/null 2>&1; then
            echo "jq or curl missing; installing..."
            sudo apt-get update -y
            sudo apt-get install -y jq curl
          fi
          echo "jq: $(jq --version)"
          echo "curl: $(curl --version | head -n1)"
          if [ ! -f "$GITHUB_WORKSPACE/scripts/verify_tenant_metrics.sh" ]; then
            echo "$GITHUB_WORKSPACE/scripts/verify_tenant_metrics.sh not found" >&2
            exit 2
          fi
          mkdir -p artifacts/metrics
          echo "Running verify_tenant_metrics.sh ..."
          bash -x "$GITHUB_WORKSPACE/scripts/verify_tenant_metrics.sh" demo

      - name: Ensure demo dataset (demo_faq.jsonl)
        run: |
          set -euo pipefail
          echo "PWD=$(pwd)"
          echo "Root listing before ensure:" && ls -la || true
          if [ -f demo_faq.jsonl ]; then
            echo "demo_faq.jsonl exists"
          elif [ -f demo_faq.jsonl.gz ]; then
            echo "Found demo_faq.jsonl.gz, inflating..."
            gunzip -c demo_faq.jsonl.gz > demo_faq.jsonl
          elif [ -f demo.jsonl ]; then
            echo "Fallback to demo.jsonl -> demo_faq.jsonl"
            cp -f demo.jsonl demo_faq.jsonl
          elif [ -f demo.jsonl.gz ]; then
            echo "Fallback to demo.jsonl.gz -> demo_faq.jsonl"
            gunzip -c demo.jsonl.gz > demo_faq.jsonl
          else
            echo "No demo jsonl found. Synthesizing minimal demo_faq.jsonl"
            printf '%s\n' \
              '{"tag":"demo","question":"What is AI Support System?","answer":"An internal demo project for metrics and RAG."}' \
              '{"tag":"demo","question":"How to contact support?","answer":"Use the /ask API or check README."}' \
              > demo_faq.jsonl
          fi
          echo "Root listing after ensure:" && ls -la || true

      - name: Prepare demo embeddings (Qdrant upsert)
        env:
          SRC_JSONL: demo_faq.jsonl
          BATCH_SIZE: "64"
          MAX_DOCS: "500"
          RAG_MODEL: ${{ env.MODEL_SMALL }}
        run: |
          bash "$GITHUB_WORKSPACE/scripts/prepare_demo_embeddings.sh"

      - name: Smoke test unified ask API
        env:
          MODEL: ${{ env.MODEL_SMALL }}
          SMOKE_VERBOSE: "1"
        run: |
          bash "$GITHUB_WORKSPACE/scripts/smoke_ask.sh"

      - name: Set gate thresholds by branch
        run: |
          set -euo pipefail
          BRANCH="${GITHUB_REF_NAME}"
          echo "Branch: $BRANCH"
          # If inputs are provided, respect them; else set by branch
          set_var() {
            local key="$1"; shift
            local input_val="$1"; shift
            local default_val="$1"; shift
            if [ -n "$input_val" ]; then
              echo "$key=$input_val" >> "$GITHUB_ENV"
            else
              echo "$key=$default_val" >> "$GITHUB_ENV"
            fi
          }

          case "$BRANCH" in
            main|master)
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.70"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.40"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "both"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "40"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "1"
              ;;
            release/*)
              # Release 候选：接近主分支的严格策略，但样本量略低以便频繁发布
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.70"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.40"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "both"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "25"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "1"
              ;;
            hotfix/*)
              # Hotfix：保持严格阈值，但要求样本量不宜过高以加快修复发布
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.65"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.35"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "both"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "15"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "1"
              ;;
            dev|develop|staging)
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.65"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.35"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "both"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "20"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "0"
              ;;
            feature/*|feat/*)
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.55"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.25"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "either"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "10"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "0"
              ;;
            *)
              # default medium strict
              set_var GATE_HIT_RATIO_MIN "${{ inputs.gate_hit_ratio_min }}" "0.65"
              set_var GATE_AVG_TOP1_MIN "${{ inputs.gate_avg_top1_min }}" "0.35"
              set_var GATE_STRICT "${{ inputs.gate_strict }}" "both"
              set_var GATE_MIN_TOTAL "${{ inputs.gate_min_total }}" "15"
              set_var GATE_REQUIRE_MIN_TOTAL "${{ inputs.gate_require_min_total }}" "0"
              ;;
          esac

      - name: RAG eval gate (pre-deploy)
        env:
          RAG_EVAL_QUERIES: demo_faq.jsonl
          RAG_TOP_K: "5"
          RAG_MODEL: ${{ env.MODEL_SMALL }}
        run: |
          bash "$GITHUB_WORKSPACE/scripts/rag_eval_gate.sh"

      - name: Backup Qdrant collection
        env:
          RAG_COLLECTION: default_collection
        run: |
          bash "$GITHUB_WORKSPACE/scripts/backup_qdrant_collection.sh"

      - name: List metrics artifacts before upload
        if: always()
        run: |
          set -euo pipefail
          echo "Listing artifacts/metrics before upload:" 
          ls -la artifacts/metrics || true
          echo "Printing ask_* if present (first 200 lines):"
          for f in artifacts/metrics/ask_*.json; do
            [ -f "$f" ] && echo "--- $f ---" && sed -n '1,200p' "$f"; done || true
          echo "Printing ask status files if present:"
          for f in artifacts/metrics/ask_*.status; do
            [ -f "$f" ] && echo "--- $f ---" && sed -n '1,40p' "$f"; done || true
          echo "Printing metrics probe files if present:" 
          for f in artifacts/metrics/metrics_*_probe.txt; do
            [ -f "$f" ] && echo "--- $f ---" && sed -n '1,120p' "$f"; done || true

      - name: Upload metrics artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-artifacts-${{ github.run_id }}-${{ github.run_attempt }}
          path: artifacts/metrics
          if-no-files-found: warn

      - name: Dump docker logs on failure
        if: failure()
        run: |
          docker ps -a
          docker compose -f docker-compose.yml logs --no-color --tail=200

      - name: Teardown
        if: always()
        run: |
          docker compose -f docker-compose.yml down -v || true
