name: Release Backup Artifacts

on:
  workflow_dispatch:
    inputs:
      run_id:
        description: "Optional: backup-restore run_id to release (defaults to latest successful)"
        required: false
        type: string
      tag:
        description: "Optional: tag name for release (defaults to auto-generated)"
        required: false
        type: string
      name:
        description: "Optional: release name (defaults to auto-generated)"
        required: false
        type: string
      force:
        description: "Force update release body even if content hash unchanged"
        required: false
        type: boolean
  workflow_run:
    workflows: ["Backup & Restore Qdrant"]
    types:
      - completed
    branches:
      - main

permissions:
  contents: write
  actions: read

jobs:
  release-backup:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    # Run when: manual, or backup-restore completed successfully on main
    if: >-
      ${{ github.event_name == 'workflow_dispatch' ||
          (github.event_name == 'workflow_run' &&
           github.event.workflow_run.conclusion == 'success' &&
           github.event.workflow_run.head_branch == 'main') }}
    env:
      # When triggered by workflow_run, provide the completed backup-restore run id
      RUN_ID: ${{ github.event.workflow_run.id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Resolve target backup-restore run
        id: resolve_run
        uses: actions/github-script@v7
        with:
          script: |
            const envRun = process.env.RUN_ID || '';
            const runInput = core.getInput('run_id');

            // Helper: find workflow by file path
            async function getWorkflowByPath(path) {
              const { data } = await github.rest.actions.listRepoWorkflows({
                owner: context.repo.owner,
                repo: context.repo.repo,
                per_page: 100,
              });
              const wf = data.workflows.find(w => w.path === path);
              if (!wf) throw new Error(`Workflow not found by path: ${path}`);
              return wf;
            }

            let runId = 0;
            if (envRun && String(envRun).trim().length) {
              runId = parseInt(String(envRun).trim(), 10);
            } else if (runInput && runInput.trim().length) {
              runId = parseInt(runInput.trim(), 10);
            }
            if (!runId) {
              const wf = await getWorkflowByPath('.github/workflows/backup-restore.yml');
              const { data } = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: wf.id,
                status: 'success',
                per_page: 1,
              });
              if (!data.workflow_runs || !data.workflow_runs.length) {
                throw new Error('No successful backup-restore runs found');
              }
              runId = data.workflow_runs[0].id;
            }

            core.setOutput('run_id', String(runId));

      - name: List artifacts for target run
        id: list_artifacts
        uses: actions/github-script@v7
        env:
          TARGET_RUN_ID: ${{ steps.resolve_run.outputs.run_id }}
        with:
          script: |
            const runIdSrc = process.env.TARGET_RUN_ID || core.getInput('run_id');
            const run_id = parseInt(runIdSrc, 10);
            const { data } = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id,
              per_page: 100,
            });
            if (!data.artifacts || !data.artifacts.length) {
              throw new Error(`No artifacts found for run ${run_id}`);
            }
            // Prefer artifact starting with 'backup-restore-' otherwise take the first
            let artifact = data.artifacts.find(a => a.name.startsWith('backup-restore-')) || data.artifacts[0];
            core.setOutput('artifact_id', String(artifact.id));
            core.setOutput('artifact_name', artifact.name);

      - name: Download artifact zip via API
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          run_id="${{ steps.resolve_run.outputs.run_id }}"
          artifact_id="${{ steps.list_artifacts.outputs.artifact_id }}"
          artifact_name="${{ steps.list_artifacts.outputs.artifact_name }}"
          out_dir="release_artifacts/${run_id}"
          mkdir -p "$out_dir"
          echo "Downloading artifact id=$artifact_id name=$artifact_name for run=$run_id"
          curl -fsSL -H "Authorization: Bearer $GH_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            -o "$out_dir/${artifact_name}.zip" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip"
          echo "Computing sha256"
          (cd "$out_dir" && shasum -a 256 "${artifact_name}.zip" | tee "${artifact_name}.zip.sha256")
          echo "out_dir=$out_dir" >> "$GITHUB_OUTPUT"

      - name: Extract artifact and generate validation summary
        run: |
          set -euo pipefail
          run_id="${{ steps.resolve_run.outputs.run_id }}"
          artifact_name="${{ steps.list_artifacts.outputs.artifact_name }}"
          out_dir="release_artifacts/${run_id}"
          extract_dir="$out_dir/extract"
          mkdir -p "$extract_dir"
          sudo apt-get update -y
          sudo apt-get install -y jq unzip
          echo "Listing zip entries"
          entries=$(unzip -Z1 "$out_dir/${artifact_name}.zip")
          echo "$entries" | sed -n '1,100p'
          echo "Extracting matched entries deterministically using unzip -p ..."
          emb_entry=$(printf "%s\n" "$entries" | grep -E '^(.*/)?embedding_upsert.json$' | head -n1 || true)
          dump_entry=$(printf "%s\n" "$entries" | grep -E '^(.*/)?qdrant_.*_dump.json$' | head -n1 || true)
          ci_entry=$(printf "%s\n" "$entries" | grep -E '^(.*/)?ci_summary.txt$' | head -n1 || true)
          emb_path=""
          dump_path=""
          if [ -n "$emb_entry" ]; then
            unzip -p "$out_dir/${artifact_name}.zip" "$emb_entry" > "$out_dir/embedding_upsert.json" || true
            emb_path="$out_dir/embedding_upsert.json"
          fi
          if [ -n "$dump_entry" ]; then
            unzip -p "$out_dir/${artifact_name}.zip" "$dump_entry" > "$out_dir/qdrant_dump.json" || true
            dump_path="$out_dir/qdrant_dump.json"
          fi
          if [ -n "$ci_entry" ]; then
            unzip -p "$out_dir/${artifact_name}.zip" "$ci_entry" > "$out_dir/ci_summary.txt" || true
          fi
          # Fallback to filesystem search only if needed
          if [ -z "$emb_path" ] || [ -z "$dump_path" ]; then
            echo "Falling back to filesystem search in extract dir..."
            unzip -o "$out_dir/${artifact_name}.zip" -d "$extract_dir" >/dev/null || true
            echo "Extraction tree (top 200 lines):"
            (cd "$extract_dir" && find . -maxdepth 4 -type f -printf '%p\n' | sed -n '1,200p') || true
            [ -z "$emb_path" ] && emb_path=$(find "$extract_dir" -type f -name 'embedding_upsert.json' | head -n1)
            [ -z "$dump_path" ] && dump_path=$(find "$extract_dir" -type f -regex '.*/qdrant_.*_dump.json' | head -n1)
          fi
          if [ -z "$emb_path" ] || [ -z "$dump_path" ]; then
            echo "embedding_upsert.json or qdrant_*_dump.json not found in artifact; writing warning summary and continuing" >&2
            {
              echo "artifact scan warning: required files not found in zip";
              echo "zip: ${artifact_name}.zip";
              echo "emb_path: $emb_path";
              echo "dump_path: $dump_path";
            } > "$out_dir/VALIDATION_SUMMARY.txt"
            exit 0
          fi
          echo "emb_path=$emb_path"
          echo "dump_path=$dump_path"
          exp_total=$(jq -r '.total' "$emb_path")
          exp_src=$(jq -r '.src' "$emb_path")
          exp_coll=$(jq -r '.collection' "$emb_path")
          echo "Derived expects: total=$exp_total src=$exp_src coll=$exp_coll"
          # Run validation script to generate a friendly summary; never fail release even if validation fails
          python3 scripts/validate_backup_artifacts.py \
            --emb "$emb_path" \
            --dump "$dump_path" \
            --expect-total "$exp_total" \
            --expect-src "$exp_src" \
            --expect-collection "$exp_coll" \
            --sample-count 3 \
            > "$out_dir/VALIDATION_SUMMARY.txt" || true

      - name: Generate release notes
        id: notes
        env:
          GH_TOKEN: ${{ github.token }}
          TAG_NAME: ${{ inputs.tag || format('backup-restore-run-{0}', steps.resolve_run.outputs.run_id) }}
        run: |
          set -euo pipefail
          run_id="${{ steps.resolve_run.outputs.run_id }}"
          artifact_name="${{ steps.list_artifacts.outputs.artifact_name }}"
          out_dir="release_artifacts/${run_id}"
          ts=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          cat > "$out_dir/RELEASE_NOTES.md" << 'EOF'
          # Backup & Restore Artifacts

          本次 Release 来源于最近一次成功的 Backup & Restore 工作流运行，包含以下内容：
          
          - 工件：ZIP 压缩包（内含 embedding_upsert.json 与 qdrant dump）
          - 完整性校验：提供 sha256 摘要文件（.sha256）
          - 运行来源：GitHub Actions backup-restore 工作流

          使用方法：
          1) 下载 ZIP 与其对应的 .sha256 文件
          2) 本地校验：`shasum -a 256 -c <artifact>.zip.sha256`
          3) 解压并按 Playbook 进行校验或恢复演练

          参考文档：docs/backup_restore_playbook.md
          EOF
          # Derive Run Metrics
          metrics_section=""
          emb_json="$out_dir/embedding_upsert.json"
          dump_json="$out_dir/qdrant_dump.json"
          coll=""
          src=""
          total=""
          restored_total=""
          if [ -f "$emb_json" ]; then
            coll=$(jq -r '.collection // empty' "$emb_json" || true)
            src=$(jq -r '.src // empty' "$emb_json" || true)
            total=$(jq -r '.total // empty' "$emb_json" || true)
          fi
          if [ -f "$dump_json" ]; then
            restored_total=$(jq -r 'if type=="object" then (.points // []) | length else length end' "$dump_json" || true)
          fi
          # RTO seconds from workflow run timing
          rto_secs=""
          run_json="$out_dir/run_${run_id}.json"
          curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${run_id}" -o "$run_json" || true
          if [ -s "$run_json" ]; then
            started=$(jq -r '.run_started_at // .created_at // empty' "$run_json" || true)
            updated=$(jq -r '.updated_at // .completed_at // empty' "$run_json" || true)
            if [ -n "$started" ] && [ -n "$updated" ]; then
              start_epoch=$(date -d "$started" +%s || true)
              end_epoch=$(date -d "$updated" +%s || true)
              if [ -n "$start_epoch" ] && [ -n "$end_epoch" ]; then
                rto_secs=$(( end_epoch - start_epoch ))
              fi
            fi
          fi
          {
            echo;
            echo "## Run Metrics";
            echo;
            [ -n "$coll" ] && echo "- collection: $coll" || true;
            [ -n "$src" ] && echo "- src: $src" || true;
            [ -n "$total" ] && echo "- seed_total: $total" || true;
            [ -n "$restored_total" ] && echo "- restored_total: $restored_total" || true;
            [ -n "$rto_secs" ] && echo "- RTO_seconds: $rto_secs" || true;
          } >> "$out_dir/RELEASE_NOTES.md"
          if [ -f "$out_dir/VALIDATION_SUMMARY.txt" ]; then
            {
              echo;
              echo "## Artifact Validation (auto-generated)";
              echo;
              echo '```text';
              cat "$out_dir/VALIDATION_SUMMARY.txt";
              echo '```';
            } >> "$out_dir/RELEASE_NOTES.md"
          fi
          if [ -f "$out_dir/ci_summary.txt" ]; then
            {
              echo;
              echo "## CI Summary";
              echo;
              echo '```text';
              cat "$out_dir/ci_summary.txt";
              echo '```';
            } >> "$out_dir/RELEASE_NOTES.md"
          fi
          # Append Key Signals section (quick glance)
          if [ -f "$out_dir/ci_summary.txt" ]; then
            ks_file="$out_dir/_key_signals.txt"
            cs="$out_dir/ci_summary.txt"
            ask_rate=$(grep -E '^- success_rate:' "$cs" | head -n1 | sed -E 's/^- success_rate: *//') || true
            llm_p95=$(grep -E '^- LLM generate p95:' "$cs" | head -n1 | sed -E 's/.*: *([0-9.]+) s.*/\1 s/') || true
            rag_p95=$(grep -E '^- RAG retrieval p95:' "$cs" | head -n1 | sed -E 's/.*: *([0-9.]+) s.*/\1 s/') || true
            llm_samples=$(grep -E '^- LLM samples:' "$cs" | head -n1 | sed -E 's/^- LLM samples: *//') || true
            rag_samples=$(grep -E '^- RAG samples:' "$cs" | head -n1 | sed -E 's/^- RAG samples: *//') || true
            # from API Success (extra) block
            upsert_rate=$(awk '
              $0 ~ /^- endpoint: \/embedding\/upsert$/ {flag=1; next}
              flag && $0 ~ /success_rate:/ { gsub(/^.*success_rate: /, ""); print; flag=0 }
            ' "$cs" | head -n1) || true
            preflight_rate=$(awk '
              $0 ~ /^- endpoint: \/api\/v1\/rag\/preflight$/ {flag=1; next}
              flag && $0 ~ /success_rate:/ { gsub(/^.*success_rate: /, ""); print; flag=0 }
            ' "$cs" | head -n1) || true
            {
              echo;
              echo "## Key Signals";
              echo;
              [ -n "$ask_rate" ] && echo "- /api/v1/ask success: $ask_rate" || true
              [ -n "$preflight_rate" ] && echo "- /api/v1/rag/preflight success: $preflight_rate" || true
              [ -n "$upsert_rate" ] && echo "- /embedding/upsert success: $upsert_rate" || true
              [ -n "$llm_p95" ] && echo "- LLM p95: $llm_p95" || true
              [ -n "$rag_p95" ] && echo "- RAG p95: $rag_p95" || true
              [ -n "$llm_samples" ] && echo "- LLM samples: $llm_samples" || true
              [ -n "$rag_samples" ] && echo "- RAG samples: $rag_samples" || true
            } >> "$out_dir/RELEASE_NOTES.md"
          fi
          # Append Run Links (metrics-e2e latest success, backup-restore source, this release)
          {
            echo;
            echo "## Run Links";
            echo;
            # backup-restore run
            echo "- backup-restore: https://github.com/${{ github.repository }}/actions/runs/${run_id}";
            # release run
            echo "- release: https://github.com/${{ github.repository }}/actions/runs/${GITHUB_RUN_ID}";
            # metrics-e2e latest success
            m_url=""
            wf_json="$out_dir/_workflows.json";
            runs_json="$out_dir/_metrics_e2e_runs.json";
            curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/workflows" -o "$wf_json" || true
            wf_id=$(jq -r '.workflows[] | select(.name=="Metrics E2E") | .id' "$wf_json" | head -n1 || true)
            if [ -n "$wf_id" ]; then
              curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${wf_id}/runs?status=success&per_page=1" -o "$runs_json" || true
              m_run=$(jq -r '.workflow_runs[0].id // empty' "$runs_json" || true)
              if [ -n "$m_run" ]; then
                m_url="https://github.com/${{ github.repository }}/actions/runs/${m_run}"
                echo "- metrics-e2e: $m_url";
              fi
            fi
          } >> "$out_dir/RELEASE_NOTES.md"
          # Decide if release notes changed compared to existing release body (after all sections appended)
          notes_hash=$(shasum -a 256 "$out_dir/RELEASE_NOTES.md" | awk '{print $1}')
          changed="true"
          tmp_rel="$out_dir/_existing_release.json"
          if curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${{ github.repository }}/releases/tags/${TAG_NAME}" -o "$tmp_rel"; then
            body=$(jq -r '.body // ""' "$tmp_rel")
            old_hash=$(printf "%s" "$body" | shasum -a 256 | awk '{print $1}')
            if [ "$old_hash" = "$notes_hash" ]; then
              changed="false"
            fi
          fi
          echo "notes_path=$out_dir/RELEASE_NOTES.md" >> "$GITHUB_OUTPUT"
          echo "changed=$changed" >> "$GITHUB_OUTPUT"

      - name: Create or Update GitHub Release (only if changed/new or forced)
        if: steps.notes.outputs.changed == 'true' || inputs.force == true
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ inputs.tag || format('backup-restore-run-{0}', steps.resolve_run.outputs.run_id) }}
          name: ${{ inputs.name || format('Backup Restore Artifacts (run {0})', steps.resolve_run.outputs.run_id) }}
          body_path: ${{ steps.notes.outputs.notes_path }}
          allowUpdates: true
          files: |
            ${{ steps.list_artifacts.outputs.artifact_name && format('release_artifacts/{0}/{1}.zip', steps.resolve_run.outputs.run_id, steps.list_artifacts.outputs.artifact_name) }}
            ${{ steps.list_artifacts.outputs.artifact_name && format('release_artifacts/{0}/{1}.zip.sha256', steps.resolve_run.outputs.run_id, steps.list_artifacts.outputs.artifact_name) }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Notify release success (Slack/Lark optional)
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          LARK_WEBHOOK_URL: ${{ secrets.LARK_WEBHOOK_URL }}
          # Default thresholds (main)
          WARN_API_SUCCESS_MIN: "98"   # percent threshold for warning
          WARN_LLM_P95_MAX: "1.8"      # seconds
          WARN_RAG_P95_MAX: "0.9"      # seconds
          # Branch name resolved from trigger (workflow_run or workflow_dispatch)
          BRANCH_NAME: ${{ github.event.workflow_run.head_branch || github.ref_name }}
        run: |
          set -euo pipefail
          # Adjust thresholds by branch patterns
          case "${BRANCH_NAME:-}" in
            release/*)
              WARN_API_SUCCESS_MIN="99"; WARN_LLM_P95_MAX="1.5"; WARN_RAG_P95_MAX="0.8" ;;
            main|master)
              WARN_API_SUCCESS_MIN="98"; WARN_LLM_P95_MAX="1.8"; WARN_RAG_P95_MAX="0.9" ;;
            dev|develop|staging)
              WARN_API_SUCCESS_MIN="95"; WARN_LLM_P95_MAX="2.2"; WARN_RAG_P95_MAX="1.2" ;;
            feature/*|feat/*)
              WARN_API_SUCCESS_MIN="95"; WARN_LLM_P95_MAX="2.5"; WARN_RAG_P95_MAX="1.5" ;;
            *)
              WARN_API_SUCCESS_MIN="98"; WARN_LLM_P95_MAX="1.8"; WARN_RAG_P95_MAX="0.9" ;;
          esac
          run_id="${{ steps.resolve_run.outputs.run_id }}"
          tag_name="${{ inputs.tag || format('backup-restore-run-{0}', steps.resolve_run.outputs.run_id) }}"
          release_url="https://github.com/${{ github.repository }}/releases/tag/${tag_name}"
          notes_path='${{ steps.notes.outputs.notes_path }}'
          # Extract a few metrics lines to include in notification
          run_metrics=$(sed -n '/^## Run Metrics$/,/^## /p' "$notes_path" | sed '1d;$d' | head -n 10 || true)
          ci_summary=$(sed -n '/^## CI Summary$/,/^## /p' "$notes_path" | sed '1d;$d' | head -n 15 || true)
          key_signals=$(sed -n '/^## Key Signals$/,/^## /p' "$notes_path" | sed '1d;$d' | head -n 10 || true)
          # Evaluate warning flags from CI Summary
          warn_msgs=()
          # API success
          if rate_line=$(printf "%s" "$ci_summary" | grep -E '^- success_rate:' | head -n1); then
            rate_num=$(printf "%s" "$rate_line" | sed -E 's/.*: ([0-9.]+)%.*/\1/')
            min_ok=${WARN_API_SUCCESS_MIN}
            awk -v r="$rate_num" -v m="$min_ok" 'BEGIN{if (r<m) exit 0; else exit 1}' || warn_msgs+=("API success < ${min_ok}%")
          fi
          # /embedding/upsert success (from extra APIs section)
          if up_line=$(printf "%s" "$ci_summary" | awk '
            $0 ~ /^- endpoint: \/embedding\/upsert$/ {flag=1; next}
            flag && $0 ~ /success_rate:/ { print; flag=0 }
          ' | head -n1); then
            up_rate=$(printf "%s" "$up_line" | sed -E 's/.*success_rate: ([0-9.]+)%.*/\1/')
            min_ok=${WARN_API_SUCCESS_MIN}
            awk -v r="$up_rate" -v m="$min_ok" 'BEGIN{if (r<m) exit 0; else exit 1}' || warn_msgs+=("/embedding/upsert success < ${min_ok}%")
          fi
          # /api/v1/rag/preflight success
          if pf_line=$(printf "%s" "$ci_summary" | awk '
            $0 ~ /^- endpoint: \/api\/v1\/rag\/preflight$/ {flag=1; next}
            flag && $0 ~ /success_rate:/ { print; flag=0 }
          ' | head -n1); then
            pf_rate=$(printf "%s" "$pf_line" | sed -E 's/.*success_rate: ([0-9.]+)%.*/\1/')
            min_ok=${WARN_API_SUCCESS_MIN}
            awk -v r="$pf_rate" -v m="$min_ok" 'BEGIN{if (r<m) exit 0; else exit 1}' || warn_msgs+=("/api/v1/rag/preflight success < ${min_ok}%")
          fi
          # Latency p95
          if llm95=$(printf "%s" "$ci_summary" | grep -E 'LLM generate p95' | sed -E 's/.*: ([0-9.]+) s.*/\1/' | head -n1); then
            awk -v v="$llm95" -v m="$WARN_LLM_P95_MAX" 'BEGIN{if (v>m) exit 0; else exit 1}' || warn_msgs+=("LLM p95 > ${WARN_LLM_P95_MAX}s")
          fi
          if rag95=$(printf "%s" "$ci_summary" | grep -E 'RAG retrieval p95' | sed -E 's/.*: ([0-9.]+) s.*/\1/' | head -n1); then
            awk -v v="$rag95" -v m="$WARN_RAG_P95_MAX" 'BEGIN{if (v>m) exit 0; else exit 1}' || warn_msgs+=("RAG p95 > ${WARN_RAG_P95_MAX}s")
          fi
          warn_head=""
          if [ ${#warn_msgs[@]} -gt 0 ]; then
            warn_head="⚠️ Warnings: ${warn_msgs[*]}\n\n"
          fi

          # Hotfix: always proceed (webhooks may be empty), avoid early-exit branch

          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            payload=$(jq -n --arg text "[AI Support] Release published: ${tag_name}\n${release_url}\n\n${warn_head}Key Signals:\n${key_signals}\n\nRun Metrics:\n${run_metrics}\n\nCI Summary:\n${ci_summary}" '{text:$text}')
            curl -fsSL -H 'Content-Type: application/json' -d "$payload" "$SLACK_WEBHOOK_URL" || true
          fi
          if [ -n "${LARK_WEBHOOK_URL:-}" ]; then
            payload=$(jq -n --arg msg "[AI Support] Release published: ${tag_name}\n${release_url}\n\n${warn_head}Key Signals:\n${key_signals}\n\nRun Metrics:\n${run_metrics}\n\nCI Summary:\n${ci_summary}" '{msg_type:"text", content:{text:$msg}}')
            curl -fsSL -H 'Content-Type: application/json' -d "$payload" "$LARK_WEBHOOK_URL" || true
          fi

      - name: Print release info
        if: always()
        run: |
          echo "Released artifacts for run: ${{ steps.resolve_run.outputs.run_id }}"
          echo "Tag: ${{ inputs.tag || format('backup-restore-run-{0}', steps.resolve_run.outputs.run_id) }}"
