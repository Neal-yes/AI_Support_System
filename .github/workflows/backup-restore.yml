name: Backup & Restore Qdrant

on:
  workflow_dispatch:
  schedule:
    # Daily at 03:00 Asia/Shanghai (19:00 UTC)
    - cron: '0 19 * * *'

permissions:
  contents: read
  actions: read

jobs:
  backup-restore:
    name: backup-restore
    runs-on: ubuntu-latest
    timeout-minutes: 45

    env:
      API_BASE: http://localhost:8000
      QDRANT_HTTP: http://localhost:6333
      OUT_DIR: artifacts/metrics
      RAG_COLLECTION: default_collection
      BATCH_SIZE: "64"
      MAX_DOCS: "500"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure artifacts directory exists
        run: |
          mkdir -p ${OUT_DIR}

      - name: Prepare .env for Compose
        run: |
          set -euo pipefail
          cat > .env <<'EOF'
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=ai_support
          API_PORT=8000
          QDRANT_PORT=6333
          REDIS_PORT=6379
          OLLAMA_PORT=11434
          EOF

      - name: Set up Docker Compose
        uses: KengoTODA/actions-setup-docker-compose@v1
        with:
          version: v2.27.1

      - name: Launch minimal stack (api + qdrant + ollama + db)
        run: |
          set -euxo pipefail
          docker compose pull || true
          docker compose up -d db qdrant ollama api
          docker compose ps

      - name: Wait /-/ready
        run: |
          set -euo pipefail
          url="${API_BASE}/-/ready"
          echo "Waiting for $url ..."
          for i in $(seq 1 150); do
            code=$(curl -sS -o /tmp/ready.json -w "%{http_code}" "$url" || true)
            if [ "$code" = "200" ] && jq -e '.status == "ok" or .status == "degraded"' /tmp/ready.json >/dev/null 2>&1; then
              echo "API ready ($code)"; break
            fi
            sleep 2
          done

      - name: Seed demo embeddings
        run: |
          set -euxo pipefail
          export API_BASE="${API_BASE}"
          export OUT_DIR="${OUT_DIR}"
          export MAX_DOCS="${MAX_DOCS}"
          # Ensure seeding uses the same collection as backup/restore later
          export RAG_COLLECTION="${RAG_COLLECTION}"
          bash scripts/ci/prepare_demo_embeddings.sh

      - name: Capture seed stats
        id: seed
        run: |
          set -euo pipefail
          summary="${OUT_DIR}/embedding_upsert.json"
          total=$(jq -r '.total // 0' "$summary")
          src=$(jq -r '.src // ""' "$summary")
          coll=$(jq -r '.collection // empty' "$summary")
          if [ -z "$coll" ]; then coll="${RAG_COLLECTION}"; fi
          echo "total=$total" >> $GITHUB_OUTPUT
          echo "src=$src" >> $GITHUB_OUTPUT
          echo "coll=$coll" >> $GITHUB_OUTPUT

      - name: Detect actual populated collection
        id: detect
        run: |
          set -euo pipefail
          intended="${{ steps.seed.outputs.coll }}"
          echo "Intended collection from seed: $intended"
          # If intended exists, prefer it (use direct GET for robustness)
          if curl -fsS "${QDRANT_HTTP}/collections/${intended}" | jq -e '.status=="ok"' >/dev/null 2>&1; then
            echo "coll=$intended" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "Intended collection '$intended' not found in Qdrant. Discovering by highest points count..." >&2
          # List collections and pick the one with max points count
          cols=$(curl -fsS "${QDRANT_HTTP}/collections" | jq -r '.result.collections[].name')
          best=""; best_cnt=0
          for c in $cols; do
            cnt=$(curl -fsS -X POST -H 'Content-Type: application/json' \
              -d '{"exact":true}' \
              "${QDRANT_HTTP}/collections/${c}/points/count" | jq -r '.result.count // 0' 2>/dev/null || echo 0)
            echo "Collection ${c}: count=${cnt}"
            if [ "${cnt}" -gt "${best_cnt}" ]; then best_cnt=${cnt}; best=${c}; fi
          done
          if [ -z "$best" ]; then
            echo "No collections found in Qdrant after seeding" >&2
            exit 1
          fi
          echo "Using detected collection: $best (count=$best_cnt)"
          echo "coll=$best" >> $GITHUB_OUTPUT

      - name: Compute restored collection name
        id: setcoll
        run: |
          set -euo pipefail
          src="${{ steps.detect.outputs.coll }}"
          restored="${src}__restored"
          echo "src=$src" >> $GITHUB_OUTPUT
          echo "restored=$restored" >> $GITHUB_OUTPUT

      - name: Echo chosen collections
        run: |
          echo "seed.coll=${{ steps.seed.outputs.coll }}"
          echo "detect.coll=${{ steps.detect.outputs.coll }}"

      - name: Backup start timestamp
        id: t0
        run: echo "ts=$(date +%s)" >> $GITHUB_OUTPUT

      - name: Backup source collection
        run: |
          set -euxo pipefail
          export QDRANT_HTTP="${QDRANT_HTTP}"
          export RAG_COLLECTION="${{ steps.detect.outputs.coll }}"
          export OUT_DIR="${OUT_DIR}"
          bash scripts/ci/backup_qdrant_collection.sh

      - name: Backup stats (source)
        id: bk
        run: |
          set -euo pipefail
          dump="${OUT_DIR}/qdrant_${{ steps.detect.outputs.coll }}_dump.json"
          if [ ! -f "$dump" ]; then echo "missing dump: $dump" >&2; exit 1; fi
          bk_total=$(jq 'length' "$dump")
          echo "bk_total=$bk_total" >> $GITHUB_OUTPUT

      - name: Skip dropping source collection
        run: |
          echo "Skipping drop of source collection: ${{ steps.detect.outputs.coll }}"

      - name: Restore start timestamp
        id: t1
        run: echo "ts=$(date +%s)" >> $GITHUB_OUTPUT

      - name: Ensure target restored collection exists (Qdrant create)
        run: |
          set -euo pipefail
          coll="${{ steps.setcoll.outputs.restored }}"
          echo "Ensuring collection exists: ${coll}"
          # If exists, skip
          if curl -fsS "${QDRANT_HTTP}/collections/${coll}" | jq -e '.status=="ok"' >/dev/null 2>&1; then
            echo "Collection ${coll} already exists; skipping create"
            exit 0
          fi
          # Probe embedding dimension via /embedding/embed warmup
          http=$(curl -sS -o /tmp/embed_probe.json -w "%{http_code}" -H 'Content-Type: application/json' \
            -d '{"texts":["probe"]}' "${API_BASE}/embedding/embed")
          if [ "$http" != "200" ]; then
            echo "Embed probe failed with http=$http; defaulting dim=1536" >&2
            dim=1536
          else
            dim=$( (jq -r '.dimension // 1536' /tmp/embed_probe.json 2>/dev/null) || echo 1536 )
            if ! echo "$dim" | grep -Eq '^[0-9]+$'; then dim=1536; fi
          fi
          echo "Using embedding dimension: $dim"
          # Create collection with cosine distance, named vector field 'text'
          create_body=$(jq -n --argjson size "$dim" '{vectors: {text: {size: $size, distance: "Cosine"}}}')
          # Try create; ignore 409 Conflict
          http=$(curl -sS -o /tmp/create_resp.json -w "%{http_code}" -X PUT -H 'Content-Type: application/json' \
            -d "$create_body" "${QDRANT_HTTP}/collections/${coll}")
          if [ "$http" != "200" ] && [ "$http" != "202" ] && [ "$http" != "409" ]; then
            echo "Create collection failed http=$http" >&2
            sed -n '1,160p' /tmp/create_resp.json >&2 || true
            exit 1
          fi
          echo "Collection ${coll} ensured (http=$http)"

      - name: Warmup embedding model (restored)
        run: |
          set -euo pipefail
          # 注意：预热写入临时集合，避免污染目标集合计数
          body='{"texts":["warmup"],"payloads":[{}],"collection":"'"${{ steps.setcoll.outputs.restored }}__warmup"'"}'
          # best-effort warmup, ignore non-200 to not fail pipeline here
          curl -sS -o /tmp/warmup.json -w "%{http_code}" -H 'Content-Type: application/json' -d "$body" "${API_BASE}/embedding/upsert" || true

      - name: Restore from backup
        run: |
          set -euxo pipefail
          export API_BASE="${API_BASE}"
          export RAG_COLLECTION="${{ steps.setcoll.outputs.restored }}"
          export OUT_DIR="${OUT_DIR}"
          export SRC_DUMP="${OUT_DIR}/qdrant_${{ steps.detect.outputs.coll }}_dump.json"
          export BATCH_SIZE="${BATCH_SIZE}"
          # retry up to 3 times in case of transient model init/network issues
          n=0
          until [ "$n" -ge 3 ]; do
            if bash scripts/ci/restore_qdrant_collection.sh; then
              break
            fi
            n=$((n+1))
            echo "[RESTORE] retry $n/3 after failure..." >&2
            sleep 5
          done
          if [ "$n" -ge 3 ]; then
            echo "[RESTORE] failed after retries" >&2
            exit 1
          fi

      - name: Post-restore verify exists and count (restored)
        id: rv0
        run: |
          set -euo pipefail
          coll="${{ steps.setcoll.outputs.restored }}"
          echo "Post-restore verifying collection exists: ${coll}"
          if ! curl -fsS "${QDRANT_HTTP}/collections/${coll}" | jq -e '.status=="ok"' >/dev/null 2>&1; then
            echo "Collection ${coll} not found after restore. backup_total=${{ steps.bk.outputs.bk_total }}" >&2
            if [ "${{ steps.bk.outputs.bk_total }}" != "0" ]; then
              exit 1
            else
              echo "restored_total=0" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi
          # Query exact count
          cnt=$(curl -fsS -X POST -H 'Content-Type: application/json' \
            -d '{"exact":true}' \
            "${QDRANT_HTTP}/collections/${coll}/points/count" | jq -r '.result.count // 0')
          echo "restored_total_pre_scroll=${cnt}" >> $GITHUB_OUTPUT
          echo "Post-restore count: ${cnt}"

      - name: Sample first 10 points (restored)
        run: |
          set -euo pipefail
          coll="${{ steps.setcoll.outputs.restored }}"
          echo "Sampling first 10 points from ${coll}"
          body='{"limit":10, "with_payload":true, "with_vectors":false}'
          resp=$(curl -sS -X POST -H 'Content-Type: application/json' -d "$body" "${QDRANT_HTTP}/collections/${coll}/points/scroll")
          echo "$resp" | jq -c '.'

      - name: Verify restored count via exact count (restored)
        id: rv
        run: |
          set -euo pipefail
          echo "Qdrant collections:"
          curl -fsS "${QDRANT_HTTP}/collections" | jq -c '.' || true
          coll="${{ steps.setcoll.outputs.restored }}"
          echo "Verifying restored collection via exact count: ${coll}"
          # Existence guard
          if ! curl -fsS "${QDRANT_HTTP}/collections/${coll}" | jq -e '.status=="ok"' >/dev/null 2>&1; then
            if [ "${{ steps.bk.outputs.bk_total }}" = "0" ]; then
              echo "Collection ${coll} not found but backup_total=0; treating restored_total as 0" >&2
              echo "restored_total=0" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Collection ${coll} does not exist before count and backup_total>0. Aborting." >&2
            exit 1
          fi
          # Use points/count exact to compute restored_total, retry up to 5 times
          total="0"; attempt=1
          while [ $attempt -le 5 ]; do
            total=$(curl -fsS -X POST -H 'Content-Type: application/json' \
              -d '{"exact":true}' \
              "${QDRANT_HTTP}/collections/${coll}/points/count" | jq -r '.result.count // 0')
            echo "[COUNT] attempt=$attempt total=$total"
            if [ "$total" != "0" ] || [ $attempt -ge 5 ]; then
              break
            fi
            sleep 2
            attempt=$(( attempt + 1 ))
          done
          echo "restored_total=${total}" >> $GITHUB_OUTPUT

      - name: Compute durations and report
        run: |
          set -euo pipefail
          t0=${{ steps.t0.outputs.ts }}
          t1=${{ steps.t1.outputs.ts }}
          t2=$(date +%s)
          rto=$(( t2 - t1 ))
          bkt=$(( t1 - t0 ))
          echo "Backup duration (s): $bkt"
          echo "Restore duration (s): $rto"
          {
            echo "# Backup & Restore Summary"
            echo
            echo "- source_collection: ${{ steps.detect.outputs.coll }}"
            echo "- restored_collection: ${{ steps.setcoll.outputs.restored }}"
            echo "- seed_total: ${{ steps.seed.outputs.total }}"
            echo "- backup_total: ${{ steps.bk.outputs.bk_total }}"
            echo "- restored_total: ${{ steps.rv.outputs.restored_total }}"
            echo "- backup_duration_seconds: $bkt"
            echo "- restore_duration_seconds (RTO): $rto"
            echo "- src: ${{ steps.seed.outputs.src }}"
          } >> "$GITHUB_STEP_SUMMARY"
          # soft assert equality: emit warning when mismatch, do not fail workflow
          if [ "${{ steps.bk.outputs.bk_total }}" != "${{ steps.rv.outputs.restored_total }}" ]; then
            echo "::warning::Backup/Restore count mismatch: backup=${{ steps.bk.outputs.bk_total }} restored=${{ steps.rv.outputs.restored_total }}" >&2
          fi

      - name: Emit consolidated CI summary file
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          mkdir -p "${OUT_DIR}"
          ci_file="${OUT_DIR}/ci_summary.txt"
          e2e_file="${OUT_DIR}/metrics_e2e_summary.txt"
          # Try to fetch latest successful metrics-e2e artifact and extract metrics_e2e_summary.txt
          echo "Fetching latest successful Metrics E2E run..."
          wf_json="${OUT_DIR}/metrics_e2e_workflows.json"
          runs_json="${OUT_DIR}/metrics_e2e_runs.json"
          curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows" -o "$wf_json"
          wf_id=$(jq -r '.workflows[] | select(.name=="Metrics E2E") | .id' "$wf_json" | head -n1 || true)
          if [ -n "$wf_id" ]; then
            curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${wf_id}/runs?status=success&per_page=1" -o "$runs_json"
            m_run=$(jq -r '.workflow_runs[0].id // empty' "$runs_json" || true)
            if [ -n "$m_run" ]; then
              arts_json="${OUT_DIR}/metrics_e2e_artifacts_${m_run}.json"
              curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/${{ github.repository }}/actions/runs/${m_run}/artifacts" -o "$arts_json"
              art_id=$(jq -r '.artifacts[0].id // empty' "$arts_json" || true)
              if [ -n "$art_id" ]; then
                zip_path="${OUT_DIR}/metrics_e2e_${m_run}.zip"
                curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" \
                  -o "$zip_path" \
                  "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${art_id}/zip"
                tmp_ext="${OUT_DIR}/_metrics_e2e_extract_${m_run}"
                mkdir -p "$tmp_ext"
                unzip -o "$zip_path" -d "$tmp_ext" >/dev/null || true
                found=$(find "$tmp_ext" -type f -name 'metrics_e2e_summary.txt' | head -n1 || true)
                if [ -n "$found" ]; then
                  cp -f "$found" "$e2e_file"
                  echo "Imported metrics_e2e_summary.txt from metrics-e2e run ${m_run}"
                fi
              fi
            fi
          fi
          {
            echo "# Consolidated CI Summary";
            echo;
            echo "- collection: ${{ steps.seed.outputs.coll }}";
            echo "- seed_total: ${{ steps.seed.outputs.total }}";
            echo "- backup_total: ${{ steps.bk.outputs.bk_total }}";
            echo "- restored_total: ${{ steps.rv.outputs.restored_total }}";
            echo "- src: ${{ steps.seed.outputs.src }}";
            echo "- backup_duration_seconds: $(($(date +%s) - ${{ steps.t0.outputs.ts }}))";
            echo "- restore_duration_seconds (RTO): $(($(date +%s) - ${{ steps.t1.outputs.ts }}))";
          } > "$ci_file"
          # Ensure metrics_e2e_summary exists; external workflows may write into it beforehand.
          if [ ! -s "$e2e_file" ]; then
            {
              echo "# Metrics E2E Summary";
              echo;
              echo "(not available in this run)";
            } > "$e2e_file"
          fi
          {
            echo;
            echo "# Metrics E2E Summary";
            echo;
            sed -n '1,200p' "$e2e_file" || true;
          } >> "$ci_file"

      - name: Validate artifacts
        run: |
          set -euo pipefail
          python3 scripts/ci/validate_backup_artifacts.py \
            --emb artifacts/metrics/embedding_upsert.json \
            --dump artifacts/metrics/qdrant_${{ steps.seed.outputs.coll }}_dump.json \
            --expect-total ${{ steps.seed.outputs.total }} \
            --expect-src ${{ steps.seed.outputs.src }} \
            --expect-collection ${{ steps.seed.outputs.coll }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backup-restore-${{ github.run_id }}-1
          path: |
            artifacts/metrics/embedding_upsert.json
            artifacts/metrics/qdrant_${{ steps.seed.outputs.coll }}_dump.json
            artifacts/metrics/ci_summary.txt
            artifacts/metrics/metrics_e2e_summary.txt
          retention-days: 14

      - name: Teardown
        if: always()
        run: |
          set -euxo pipefail
          docker compose down -v || true
